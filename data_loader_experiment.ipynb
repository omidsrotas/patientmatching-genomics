{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import Sampler\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "import logging\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the DemographicDataset and GenomicsDataset into one dataset class\n",
    "class PatientDataset(Dataset):\n",
    "    def __init__(self, genomics_data, demographic_data,labels_df,\n",
    "                 small_molecule_embeddings, large_molecule_embeddings,\n",
    "                  cancer_types, patient_ids, ethnicity):\n",
    "        self.genomics_data = genomics_data\n",
    "        self.demographic_data = demographic_data\n",
    "        self.cancer_types = cancer_types\n",
    "        self.patient_ids = patient_ids\n",
    "        self.labels_df = labels_df\n",
    "        self.small_molecule_embeddings = small_molecule_embeddings\n",
    "        self.large_molecule_embeddings = large_molecule_embeddings\n",
    "        self.ethnicity = {key[0]: i  for i, key in enumerate(ethnicity.items())}\n",
    "    def __len__(self):\n",
    "        return len(self.patient_ids)\n",
    "    \n",
    "    def process_demographics(self):\n",
    "        # divide age by 50 --> normalize the age by 50\n",
    "        # divide weight by 100 --> normalize the age by 100\n",
    "        self.demographic_data['AGE'] = self.demographic_data['AGE'] / 50\n",
    "        self.demographic_data['WEIGHT_AT_START_OF_REGIMEN'] = self.demographic_data['WEIGHT_AT_START_OF_REGIMEN'] / 100\n",
    "\n",
    "    def extract_drug_embedding_and_label(self, idx):\n",
    "        label_patients = self.labels_df[self.labels_df['ENCORE_PATIENT_ID'].isin([idx])]\n",
    "        label_patients.drop_duplicates(subset=['ENCORE_PATIENT_ID'], inplace=True)\n",
    "        y_label = label_patients['Label'].values\n",
    "        # Explicit sizes for small and large molecule embeddings\n",
    "        SMALL_MOLECULE_SIZE = 768\n",
    "        LARGE_MOLECULE_SIZE = 1024\n",
    "        drug_embed_large = np.zeros(LARGE_MOLECULE_SIZE)\n",
    "        drug_embed_small = np.zeros(SMALL_MOLECULE_SIZE)\n",
    "        if len(label_patients['BENCHMARK_GROUP'].tolist()) > 0:\n",
    "            treatment = label_patients['BENCHMARK_GROUP'].tolist()[0]\n",
    "            # Extract only the string parts from treatment\n",
    "            drugs = re.findall(r'\\b\\w+\\b', treatment)\n",
    "            for drug in drugs:\n",
    "                if drug not in self.small_molecule_embeddings.keys():\n",
    "                    \" extract the drug embedding from the large molecule embeddings\"\n",
    "                    if drug  in self.large_molecule_embeddings.keys():\n",
    "                        drug_embed_large += self.large_molecule_embeddings[drug]\n",
    "                else:\n",
    "                    \" extract the drug embedding from the small molecule embeddings\"\n",
    "                    drug_embed_small += self.small_molecule_embeddings[drug]       \n",
    "        else:\n",
    "            y_label = np.array([])\n",
    "        return drug_embed_small,drug_embed_large, y_label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        self.process_demographics()\n",
    "        #print(\"idx: \", idx)\n",
    "        patient_genome = self.genomics_data[self.genomics_data['PATIENTID'].isin([idx])]\n",
    "        patient_genome.drop(columns=['PATIENTID',  'TUMOURID', 'ETHNICITY'], inplace=True)\n",
    "        patient_genome = patient_genome.values\n",
    "        \n",
    "        patient_demographics = self.demographic_data[self.demographic_data['PATIENTID'].isin([idx])]\n",
    "        patient_demographics.drop(columns=['PATIENTID',  'ENCORE_PATIENT_ID'], inplace=True)\n",
    "        patient_demographics['Cancer Type'] = patient_demographics['Cancer Type'].apply(lambda x: self.cancer_types[x])\n",
    "        # convert ethnicity to integer using the ethnicity dictionary\n",
    "        #patient_demographics['ETHNICITY'] = patient_demographics['ETHNICITY'].map(self.ethnicity)\n",
    "        patient_demographics.drop(columns=['ETHNICITY'], inplace=True)\n",
    "        #patient_demographics['Ethnicity'] = patient_demographics['Ethnicity'].apply(lambda x: self.cancer_types[x])\n",
    "        patient_demographics = patient_demographics.values\n",
    "        drug_embed_small,drug_embed_large, y_label = self.extract_drug_embedding_and_label(idx)\n",
    "        # if drug_embedding is 0, then do not include the patient in the dataset\n",
    "        #if not y_label.any == 0:\n",
    "        #    y_label = -1\n",
    "        #    drug_embed_small = -1*np.ones_like(drug_embed_small)\n",
    "        #    drug_embed_large = -1*np.ones_like(drug_embed_large)\n",
    "        patient_data = {'patient_id': idx,\n",
    "                        'genome': patient_genome,\n",
    "                        'demographics': patient_demographics,\n",
    "                        'drug_embed_small': drug_embed_small,\n",
    "                        'drug_embed_large': drug_embed_large,\n",
    "                        'label': y_label}\n",
    "        return patient_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the BalancedBatchSampler class\n",
    "class EthnicityBalancedSampler(Sampler):\n",
    "    def __init__(self, genomics_data, batch_size):\n",
    "        self.genomics_data = genomics_data\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Group indices by ehtnicity\n",
    "        self.groups = self.genomics_data.groupby('ETHNICITY')['PATIENTID'].apply(list).to_dict()\n",
    "        # ensure batch size can accomodate all groups\n",
    "        assert self.batch_size >= len(self.groups.keys()), (\n",
    "            'Batch size must be greater than or equal to the number of groups'\n",
    "        )\n",
    "    def __iter__(self):\n",
    "        indices = []\n",
    "        # Shuffle each ethinicity group\n",
    "        group_indices = {eth: random.sample(indices, len(indices)) \n",
    "                         for eth, indices in self.groups.items()}\n",
    "        \n",
    "        # create batches\n",
    "        while any(group_indices.values()):\n",
    "            batch = []\n",
    "            for eth, idx_list in group_indices.items():\n",
    "                if idx_list:\n",
    "                    batch.append(idx_list.pop()) # Take one sample from each group\n",
    "            # Add additional samples to fill the batch size\n",
    "            while len(batch) < self.batch_size:\n",
    "                availabel_ethnicities = [eth for eth, idx_list in group_indices.items() if idx_list]\n",
    "                if not availabel_ethnicities:\n",
    "                    break\n",
    "                eth = random.choice(availabel_ethnicities)\n",
    "                batch.append(group_indices[eth].pop())\n",
    "            yield batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        total_samples = sum(len(indices) for indices in self.ethnicity_groups.values())\n",
    "        return total_samples // self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/azureuser/cloudfiles/code/Users/Omid.Bazgir/data/'\n",
    "# read the genomics data as the pickle file\n",
    "with open(data_dir + 'patient_data.pkl', 'rb') as f:\n",
    "    patient_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the label data and drug data as pickle files\n",
    "with open(data_dir + 'label_pickle.pkl', 'rb') as f:\n",
    "    label_data = pickle.load(f)\n",
    "with open(data_dir + 'drug_data_embedding.pkl', 'rb') as f:\n",
    "    drug_data = pickle.load(f)\n",
    "small_molecule_embeddings = drug_data['small_molecule']\n",
    "large_molecule_embeddings = drug_data['large_molecule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = label_data['weak_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomics_data = patient_data['genomics']\n",
    "demographic_data = patient_data['demographic']\n",
    "# fillna in the ETHINICITY with the most frequent value\n",
    "demographic_data['ETHNICITY'].fillna('White', inplace=True)\n",
    "# Add ETHNICITY to the genomics data using the patient_id\n",
    "genomics_data = genomics_data.merge(demographic_data[['PATIENTID', 'ETHNICITY']], on='PATIENTID', how='left')\n",
    "\n",
    "cancer_types = {}\n",
    "for i, cancer in enumerate(demographic_data['Cancer Type'].unique().tolist()):\n",
    "    cancer_types[cancer] = i\n",
    "\n",
    "# read ethnicity data from the json file\n",
    "with open(data_dir + 'ethnicity.json', 'r') as json_file:\n",
    "    Ethnicity = json.load(json_file)\n",
    "\n",
    "# read the config (yaml) file\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "config['genome_encoder']['input_dim'] = genomics_data.shape[1] - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(filename='training.log', level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define batch size\n",
    "batch_size = config['train_param']['batch_size']\n",
    "\n",
    "# Create DataLoader\n",
    "\n",
    "# create a dataloader\n",
    "patient_ids = genomics_data['PATIENTID'].unique().tolist()\n",
    "labels_df = labels_df[labels_df['ENCORE_PATIENT_ID'].isin(patient_ids)]\n",
    "labels_df = labels_df.drop_duplicates(subset=['ENCORE_PATIENT_ID'], keep='first')\n",
    "patient_ids = labels_df['ENCORE_PATIENT_ID'].unique().tolist()\n",
    "# split the patient_ids into train and test\n",
    "patient_train_ids, patient_test_ids = train_test_split(patient_ids, test_size=0.2, random_state=42)\n",
    "genomics_data_train = genomics_data[genomics_data['PATIENTID'].isin(patient_train_ids)]\n",
    "demographic_data_train = demographic_data[demographic_data['PATIENTID'].isin(patient_train_ids)]\n",
    "labels_df_train = labels_df[labels_df['ENCORE_PATIENT_ID'].isin(patient_train_ids)]\n",
    "\n",
    "\n",
    "genomics_data_test = genomics_data[genomics_data['PATIENTID'].isin(patient_test_ids)]\n",
    "demographic_data_test = demographic_data[demographic_data['PATIENTID'].isin(patient_test_ids)]\n",
    "labels_df_test = labels_df[labels_df['ENCORE_PATIENT_ID'].isin(patient_test_ids)]\n",
    "sampler_train = EthnicityBalancedSampler(genomics_data_train, batch_size)\n",
    "patient_dataset_train = PatientDataset(genomics_data_train, demographic_data_train, \n",
    "                                       labels_df_train,small_molecule_embeddings, large_molecule_embeddings,\n",
    "                                        cancer_types, patient_train_ids, Ethnicity)\n",
    "patient_dataloader_train = DataLoader(patient_dataset_train, batch_sampler= sampler_train)\n",
    "\n",
    "sampler_test = EthnicityBalancedSampler(genomics_data_test, batch_size)\n",
    "patient_dataset_test = PatientDataset(genomics_data_test, demographic_data_test, \n",
    "                                      labels_df_test,small_molecule_embeddings, large_molecule_embeddings,\n",
    "                                      cancer_types, patient_test_ids, Ethnicity)\n",
    "patient_dataloader_test = DataLoader(patient_dataset_test, batch_sampler= sampler_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3949/2345788966.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.demographic_data['AGE'] = self.demographic_data['AGE'] / 50\n",
      "/tmp/ipykernel_3949/2345788966.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.demographic_data['WEIGHT_AT_START_OF_REGIMEN'] = self.demographic_data['WEIGHT_AT_START_OF_REGIMEN'] / 100\n",
      "/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "/tmp/ipykernel_3949/2345788966.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  patient_demographics['Cancer Type'] = patient_demographics['Cancer Type'].apply(lambda x: self.cancer_types[x])\n",
      "/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for batch in patient_dataloader_train:\n",
    "    a = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
